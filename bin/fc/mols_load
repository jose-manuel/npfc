#!/usr/bin/env python

"""
Script load_mols
==========================
This script is used for loading molecules from SDF, CSV or HDF files and then
export them to CSV or HDF files with RDKit Mol objects.
"""

# standard
from pathlib import Path
import sys
import warnings
from datetime import datetime
import logging
import argparse
# data
import pandas as pd
# chemoinformatics
import rdkit
from rdkit import RDLogger
# custom libraries
import npfc
from npfc import load
from npfc import save
from npfc import utils


# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ FUNCTIONS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #


def main():

    # init
    d0 = datetime.now()
    description = """Script used for loading molecules from SDF, CSV or HDF files, convert them into RDKit objects and export them into CSV or HDF files.
    Molecules that failed the RDKit conversion have None for structure but their properties, if any, remain.

    It uses the installed npfc libary in your favorite env manager.

    Examples:

        >>> # Convert a SDF into a HDF using molecule titles as molecule id
        >>> load_mols file_in.sdf file_out.hdf --col_idm _Name
        >>> # Chunk a CSV file into SDF files of 100 randomly ordered records while keeping all properties
        >>> load_mols file_in.csv file_out.sdf -n 100 -k True -s True --col_idm prop1 --col_mol mol --col_idm _Name
    """

    # parameters CLI

    parser = argparse.ArgumentParser(description=description, formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument('input_mols', type=str, default=None, help="Input file.")
    parser.add_argument('output_mols', type=str, default=None, help="Output file. If chunking, then it is used as prefix.")
    parser.add_argument('-k', '--keep_props', action='store_true', help="Keep all properties found in the source in the output, in addition to idm and mol columns.")
    parser.add_argument('--no-encoding', action='store_true', help="Do not encode objects into base64 strings in output.")
    parser.add_argument('--no-decoding', action='store_true', help="Do not parse encoded objects into base64 strings in input.")
    parser.add_argument('--col-idm', type=str, default='idm', help="Identifier column in the source file, will lead to idm column in the output.")
    parser.add_argument('--col-mol', type=str, default='mol', help="Molecule column in the source file, will lead to mol column in the output.")
    parser.add_argument('--csv-sep', type=str, default='|', help="Separator to use in case the input file is a csv.")
    parser.add_argument('--log', type=str, default='INFO', help="Specify level of logging. Possible values are: CRITICAL, ERROR, WARNING, INFO, DEBUG.")
    args = parser.parse_args()

    # logging

    logger = utils._configure_logger(args.log)
    logger.info("RUNNING LOAD_MOLS")
    warnings.filterwarnings('ignore', category=pd.io.pytables.PerformanceWarning)  # if None is returned instead of a molecule, do not complain about mixed types
    pad = 40
    lg = RDLogger.logger()
    lg.setLevel(RDLogger.CRITICAL)

    # parse arguments

    # check on args values not already checked by argparse
    if ',' in args.input_mols:
        input_files = [x.strip() for x in args.input_mols.split(',')]
    elif Path(args.input_mols).is_file():
        input_files = [args.input_mols]
    elif Path(args.input_mols).is_dir():
        input_files = sorted([str(x) for x in Path(args.input_mols).glob('*')])
    else:
        raise ValueError('ERROR! DOES NOT KNOW WHAT TO DO WITH INPUT MOLS (%s)' % args.input_mols)

    if len(input_files) < 1:
        raise ValueError('ERROR! COULD NOT FIND ANY INPUT MOLS AT "%s"' % args.input_mols)

    for input_file in input_files:
        utils.check_arg_input_file(input_file)

    utils.check_arg_output_file(args.output_mols)
    # src infos
    in_format, in_compression = utils.get_file_format(input_files[0])  # input files are supposed to be homogeneous
    # out infos
    out_format, out_compression = utils.get_file_format(args.output_mols)

    # encode
    if args.no_encoding:
        encode = False
    else:
        encode = True

    # decode
    if args.no_decoding:
        decode = False
    else:
        decode = True

    # display infos

    # versions
    logger.info("LIBRARY VERSIONS")
    logger.info("rdkit".ljust(pad) + f"{rdkit.__version__}")
    logger.info("pandas".ljust(pad) + f"{pd.__version__}")
    logger.info("npfc".ljust(pad) + f"{npfc.__version__}")
    # arguments
    logger.info("ARGUMENTS")
    if len(input_files) > 1:
        for i, input_file in enumerate(input_files):
            logger.info(f"INPUT_FILE {str(i+1).zfill(2)}".ljust(pad) + f"{input_file}")
    else:
        logger.info("INPUT_FILE".ljust(pad) + f"{input_files[0]}")
    logger.info("OUTPUT_MOLS".ljust(pad) + f"{args.output_mols}")
    logger.info("KEEP_PROPS".ljust(pad) + f"{args.keep_props}")
    logger.info("ENCODE".ljust(pad) + f"{encode}")
    logger.info("DECODE".ljust(pad) + f"{decode}")
    logger.info("col_idm".ljust(pad) + f"{args.col_idm}")
    logger.info("col_mol".ljust(pad) + f"{args.col_mol}")
    logger.info("IN_FORMAT".ljust(pad) + f"{in_format}")
    logger.info("IN_COMPRESSION".ljust(pad) + f"{in_compression}")
    logger.info("OUT_FORMAT".ljust(pad) + f"{out_format}")
    logger.info("OUT_COMPRESSION".ljust(pad) + f"{out_compression}")
    logger.info("LOG".ljust(pad) + f"{args.log}")

    # begin
    logger.info("BEGIN")

    # load mols
    logger.info("LOADING MOLECULES")
    d1 = datetime.now()
    dfs = []
    num_failed = 0
    for input_file in input_files:

        # load DF_ini
        logger.info("NOW LOADING %s", input_file)
        df = load.file(input_file,
                       col_idm=args.col_idm,
                       col_mol=args.col_mol,
                       keep_props=args.keep_props,
                       decode=decode,
                       csv_sep=args.csv_sep,
                       )
        num_tot = len(df)

        # filter out failed molecules from DF_ini
        df_failed = df[df['mol'].isna()]
        num_failed += len(df_failed.index)
        if num_failed > 0:
            logger.info("RECORD IDS THAT FAILED PARSING:\n%s", ','.join(df_failed['idm']))
            df = df[~ df.index.isin(df_failed.index)]
        
        # append truly loaded mols to main DF_mols
        dfs.append(df)
        num_loaded = len(df)
        logger.info(f"{input_file}".ljust(int(pad * 2.2)) + f"LOADED {num_loaded:,}/{num_tot:,}")
        logger.debug("FIRST THREE LOADED RECORDS:\n\n%s\n", df.head(3))

    df_mols = pd.concat(dfs)
    logger.info(f"IN TOTAL, LOADED {len(df_mols):,} RECORDS WITH {num_failed:,} FAILURE(S)")

    # save mols
    d2 = datetime.now()
    logger.info("SAVING MOLECULES")
    output_file = save.file(df_mols,
                            args.output_mols,
                            # col_mol=args.col_mol,
                            # col_idm=args.col_idm,
                            encode=encode,
                            csv_sep=args.csv_sep,
                            )
    
    # display results
    logger.info(f"SAVED {output_file[1]:,} RECORDS AT {output_file[0]}")
    d3 = datetime.now()

    # end

    logger.info("SUMMARY")
    logger.info("COMPUTATIONAL TIME: CONFIGURING JOB".ljust(pad * 2) + f"{d1-d0}")
    logger.info("COMPUTATIONAL TIME: LOADING MOLECULES".ljust(pad * 2) + f"{d2-d1}")
    logger.info("COMPUTATIONAL TIME: SAVING MOLECULES".ljust(pad * 2) + f"{d3-d2}")
    logger.info("COMPUTATIONAL TIME: TOTAL".ljust(pad * 2) + f"{d3-d0}")
    logger.info("END")
    sys.exit(0)
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ RUN ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #


if __name__ == '__main__':
    main()
