#!/usr/bin/env python

"""
Script fct_assay
=============================
This script generates the assay nodes file for a given input chunk.
"""
import argparse
from datetime import datetime
import sys
# data
import pandas as pd
# chemoinformatics
import rdkit
# dev
import npfc
from npfc import load
from npfc import save
from npfc import utils


# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ FUNCTIONS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #


def main():

    # init
    d0 = datetime.now()
    description = """Script for generating the assay nodes table.
    Rather than directly using the raw table, I prefer to filter it with the
    molecule ids found in the provided chunk. This will hopefully prevents from
    having a lot of single nodes in the network.

    Example:

        >>> fct_assay fct/data/03_synthetic/molecule.csv.gz dataset/12_pnp/data/file.csv.gz fct/assay.csv.gz

    """

    # parameters CLI
    parser = argparse.ArgumentParser(description=description, formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument('input_assay_table', type=str, default=None, help="The input raw assay table.")
    parser.add_argument('input_molecule_assay_table', type=str, default=None, help="The input molecule-assay table.")
    parser.add_argument('output_table', type=str, default=None, help="Output file with the assay table.")
    parser.add_argument('--log', type=str, default='INFO', help="Specify level of logging. Possible values are: CRITICAL, ERROR, WARNING, INFO, DEBUG.")
    args = parser.parse_args()

    # logging
    logger = utils._configure_logger(args.log)
    logger.info("RUNNING FCT_ASSAY")
    pad = 40

    # parse arguments
    utils.check_arg_input_file(args.input_assay_table)
    utils.check_arg_input_file(args.input_molecule_assay_table)
    utils.check_arg_output_file(args.output_table)

    # display infos

    # versions
    logger.info("LIBRARY VERSIONS:")
    logger.info("rdkit".ljust(pad) + f"{rdkit.__version__}")
    logger.info("pandas".ljust(pad) + f"{pd.__version__}")
    logger.info("npfc".ljust(pad) + f"{npfc.__version__}")
    # arguments
    logger.info("ARGUMENTS:")
    logger.info("INPUT_ASSAY_TABLE".ljust(pad) + f"{args.input_assay_table}")
    logger.info("INPUT_MOLECULE_TABLE".ljust(pad) + f"{args.input_molecule_assay_table}")
    logger.info("OUTPUT_ASSSAY_TABLE".ljust(pad) + f"{args.output_table}")
    # log
    logger.info("LOG".ljust(pad) + f"{args.log}")

    # begin

    logger.info("BEGIN")
    d1 = datetime.now()

    # load inputs
    logger.info("LOADING INPUT FILES")
    df_assay_raw = load.file(args.input_assay_table).fillna('')
    logger.info(f"LOADED {len(df_assay_raw):,} ASSAY NODES")
    df_molecule_assay = load.file(args.input_molecule_assay_table)[['assay_id']]
    logger.info(f"LOADED {len(df_molecule_assay):,} MOLECULE-ASSAY RELATIONSHIPS")
    d2 = datetime.now()

    # process data
    df_assay = df_assay_raw[df_assay_raw['assay_id'].isin(df_molecule_assay['assay_id'])]
    logger.info(f"REMAINING NUMBER OF ASSAY NODES: {len(df_assay)}")
    d3 = datetime.now()

    # save file
    logger.info("SAVING OUTPUT")
    save.file(df_assay, args.output_table)
    d4 = datetime.now()

    # end

    logger.info("SUMMARY")
    logger.info("COMPUTATIONAL TIME: CONFIGURING JOB".ljust(pad * 2) + f"{d1-d0}")
    logger.info("COMPUTATIONAL TIME: LOADING INPUTS".ljust(pad * 2) + f"{d2-d1}")
    logger.info("COMPUTATIONAL TIME: PROCESSING DATA".ljust(pad * 2) + f"{d3-d2}")
    logger.info("COMPUTATIONAL TIME: SAVING OUTPUT".ljust(pad * 2) + f"{d4-d3}")
    logger.info("COMPUTATIONAL TIME: TOTAL".ljust(pad * 2) + f"{d4-d0}")
    logger.info("END")
    sys.exit(0)


# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ MAIN ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #


if __name__ == '__main__':
    main()
    sys.exit(0)
