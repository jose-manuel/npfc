#!/usr/bin/env python

"""
Script annotate_pnp
==========================
This script is used for annotating Pseudo Natural Products (PNP).
"""

# standard
import warnings
import sys
from datetime import datetime
import logging
import pandas as pd
import argparse
from pathlib import Path
# chemoinformatics
import rdkit
# dev
import npfc
from npfc import load
from npfc import save
from npfc import utils
from npfc import fragment_graph
# disable SettingWithCopyWarning warnings
pd.options.mode.chained_assignment = None  # default='warn'


# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ FUNCTIONS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #


def label_pnp_maps(df, df_ref):
    """Iterate over df and df_ref graphs to see if molecules in df are pseudo-natural-products
    in regards to df_ref, which contains only natural products.

    As the input dataframes contain 1 fragment map per row, a same molecule might be
    labelled both as PNP and non-PNP (respect. True and False).

    The refining of these results by groupbing entries by idm is performed outside
    of this function.

    """
    results = []
    for i in range(len(df.index)):
        edges = df.iloc[i]['_fgraph'].edges(data='abbrev')
        pnp = True
        for j in range(len(df_ref.index)):
            # if all edges of tested mol are present in ref edges, then it is not PNP
            if all(edge_ref in edges for edge_ref in df_ref.iloc[j]['edges_ref']):
                pnp = False
                logging.debug(f"FGRAPH {df.iloc[i]['idm']}#{df.iloc[i]['fmid']} IS NOT PNP BECAUSE OF REF FGRAPH{ df_ref.iloc[j]['idm']}#{df_ref.iloc[j]['fmid']}")
                break

        results.append(pnp)

    return results


def _label_pnp_mols(group):
    """Applied on the group of fragment map dataframe after annotation by pnp_fm.
    If any map of a molecule has a label set to True, then the molecule should be considered
    as PNP, even if some maps are not True.
    """
    if any(group["pnp_fm"]):
        group["pnp_mol"] = True
    else:
        group["pnp_mol"] = False

    return group


def main():

    # init
    d0 = datetime.now()
    description = """Script is used for annotating Pseudo Natural Products (PNP).

    It takes two inputs:
        - the map file with the molecules to annotate by comparing fragment maps (graphs)
        - a folder that contains molecular files of natural products

    It creates one output:
        - the input molecular file annotated with a new column "pnp" valuing either True or False.

    It uses the installed npfc libary in your favorite env manager.

    Example:

        >>> annotate_pnp file_map.csv.gz file_map.csv.gz

    """

    # parameters CLI
    parser = argparse.ArgumentParser(description=description, formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument('input_map', type=str, default=None, help="Fragment Map file to annotate")
    parser.add_argument('ref_dir', type=str, default=None, help="Directory with Fragment Map files to use as references (currently wiht syntax: <name>_map.csv.gz)")
    parser.add_argument('output_map', type=str, default=None, help="Output file basename. It gets appended with the type of output being produced: raw, clean and map.")
    parser.add_argument('--log', type=str, default='INFO', help="Specify level of logging. Possible values are: CRITICAL, ERROR, WARNING, INFO, DEBUG.")
    args = parser.parse_args()

    # logging
    logger = utils._configure_logger(args.log)
    logger.info("RUNNING PNP ANNOTATION")
    warnings.filterwarnings('ignore', category=pd.io.pytables.PerformanceWarning)  # if None is returned instead of a molecule, do not complain about mixed types
    pad = 40

    # parse arguments
    utils.check_arg_input_file(args.input_map)
    utils.check_arg_output_file(args.output_map)
    input_format, input_compression = utils.get_file_format(args.input_map)
    out_format, out_compression = utils.get_file_format(args.output_map)

    # get the list of reference files
    p = Path(args.ref_dir)
    if not p.is_dir():
        raise ValueError(f"ERROR! REF_DIR COULD NOT BE FOUND! ({args.ref_dir})")
    ref_files = [str(x) for x in list(p.glob("*_fgraph.csv.gz"))]
    ref_files.sort()
    logger.info(f"FOUND {len(ref_files)} FRAGMENT MAP FILES AT {args.ref_dir}")

    # display infos
    logger.info("LIBRARY VERSIONS:")
    logger.info("rdkit".ljust(pad) + f"{rdkit.__version__}")
    logger.info("pandas".ljust(pad) + f"{pd.__version__}")
    logger.info("npfc".ljust(pad) + f"{npfc.__version__}")
    logger.info("ARGUMENTS:")
    logger.info("INPUT_FCC".ljust(pad) + f"{args.input_map}")
    logger.info("INPUT_FORMAT".ljust(pad) + f"{input_format}")
    logger.info("INPUT_COMPRESSION".ljust(pad) + f"{input_compression}")
    logger.info("REF_DIR".ljust(pad) + f"{args.ref_dir}")
    logger.info("NUM REF_DIR".ljust(pad) + f"{len(ref_files)}")
    logger.info("OUTPUT_MAP".ljust(pad) + f"{args.output_map}")
    logger.info("OUT_FORMAT".ljust(pad) + f"{out_format}")
    logger.info("OUT_COMPRESSION".ljust(pad) + f"{out_compression}")
    logger.info("LOG".ljust(pad) + f"{args.log}")
    d1 = datetime.now()

    # begin
    logger.info("BEGIN")

    # load map
    logger.info("LOADING FRAGMENT GRAPHS")
    df_fgraph = load.file(args.input_map, decode=True)
    n_fragment_graphs = len(df_fgraph.index)
    logger.info(f"FOUND {n_fragment_graphs:,} FRAGMENT GRAPHS")
    d2 = datetime.now()

    # avoid crash due to groupby method on empty dataframe
    if n_fragment_graphs < 1:
        logger.warning("NO FRAGMENT GRAPHS TO WORK WITH, ABORTING NOW. EMPTY OUTPUT FILE IS GENERATED FOR PIPELINE HANDLING.")
        df_fgraph = pd.DataFrame(columns=fragment_graph.DF_PNP_COLS)
        # saving results
        logger.info("SAVING RESULTS")
        d5 = datetime.now()
        logger.info(f"SAVING PNP RESULTS AT '{args.output_map}'")
        save.file(df_fgraph, args.output_map, encode=True)
        # end
        d6 = datetime.now()
        logger.info("SUMMARY")
        logger.info("COMPUTATIONAL TIME: CONFIGURING JOB".ljust(pad * 2) + f"{d1-d0}")
        logger.info("COMPUTATIONAL TIME: LOADING INPUT FRAGMENT GRAPHS".ljust(pad * 2) + f"{d2-d1}")
        logger.info("COMPUTATIONAL TIME: SAVING ANNOTATED FRAGMENT GRAPHS".ljust(pad * 2) + f"{d5-d2}")
        logger.info("COMPUTATIONAL TIME: DISPLAYING RESULTS".ljust(pad * 2) + f"{d6-d5}")
        logger.info("COMPUTATIONAL TIME: TOTAL".ljust(pad * 2) + f"{d6-d0}")
        logger.info("END")
        return None

    # load map_refs
    logger.info("LOADING ALL REFERENCE FRAGMENT GRAPHS")
    df_fgraph_ref = pd.concat([load.file(x) for x in ref_files])
    # df_fgraph_ref.drop("Unnamed: 0", axis=1, inplace=True)
    logger.info(f"FOUND {len(df_fgraph_ref.index):,} REFERENCE FRAGMENT GRAPHS")
    logger.info("EXTRACTING EDGES FROM FRAGMENT GRAPHS")
    df_fgraph_ref["edges_ref"] = df_fgraph_ref["_fgraph"].map(lambda x: x.edges(data="abbrev"))

    # mapping fragment combinations
    logger.info("ANNOTATING FRAGMENT GRAPHS")
    d3 = datetime.now()
    df_fgraph["pnp_fm"] = label_pnp_maps(df_fgraph, df_fgraph_ref)

    logger.info("DISPLAYING RESULTS")
    d4 = datetime.now()
    # pnps
    df_pnps = df_fgraph[df_fgraph["pnp_fm"]].groupby("idm").first().reset_index()[["idm"]]
    logger.info("=" * pad)
    logger.info(f"LIST OF PNPs ({len(df_pnps.index)})".center(pad))
    logger.info("=" * pad)
    [logger.info(f"PNP: {df_pnps.iat[i, 0]}") for i in range(len(df_pnps.index))]
    # others
    df_others = df_fgraph[~df_fgraph["idm"].isin(df_pnps['idm'])].groupby("idm").first().reset_index()[["idm"]]
    logger.info("=" * pad)
    logger.info(f"LIST OF NON-PNPs ({len(df_others.index)})".center(pad))
    logger.info("=" * pad)
    [logger.info(f"NON-PNP: {df_others.iat[i, 0]}") for i in range(len(df_others.index))]
    logger.info("=" * pad)

    # curating results
    logger.info("CURATING RESULTS")
    df_fgraph['pnp_mol'] = df_fgraph.groupby('idm').apply(_label_pnp_mols)['pnp_mol']  # cringy but works.... ok for now...

    # saving results
    logger.info("SAVING RESULTS")
    d5 = datetime.now()
    logger.info(f"SAVING PNP RESULTS AT '{args.output_map}'")
    save.file(df_fgraph, args.output_map, encode=True)

    # end
    d6 = datetime.now()
    logger.info("SUMMARY")
    logger.info("COMPUTATIONAL TIME: CONFIGURING JOB".ljust(pad * 2) + f"{d1-d0}")
    logger.info("COMPUTATIONAL TIME: LOADING INPUT FRAGMENT GRAPHS".ljust(pad * 2) + f"{d2-d1}")
    logger.info("COMPUTATIONAL TIME: LOADING REFERENCE FRAGMENT GRAPHS".ljust(pad * 2) + f"{d3-d2}")
    logger.info("COMPUTATIONAL TIME: ANNOTATING FRAGMENT GRAPHS".ljust(pad * 2) + f"{d4-d3}")
    logger.info("COMPUTATIONAL TIME: SAVING ANNOTATED FRAGMENT GRAPHS".ljust(pad * 2) + f"{d5-d4}")
    logger.info("COMPUTATIONAL TIME: DISPLAYING RESULTS".ljust(pad * 2) + f"{d6-d5}")
    logger.info("COMPUTATIONAL TIME: TOTAL".ljust(pad * 2) + f"{d6-d0}")
    logger.info("END")


# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ MAIN ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #


if __name__ == '__main__':
    main()
    sys.exit(0)
